---
description: >-
  For those already familiar with LLM application tech stacks, this document
  serves as a shortcut to understand Dify's unique advantages
---

# Specifications and Technical Features

We adopt transparent policies around product specifications to ensure decisions are made based on complete understanding. Such transparency not only benefits your technical selection, but also promotes deeper comprehension within the community for active contributions.

### Project Basics

<table data-header-hidden><thead><tr><th width="341"></th><th></th></tr></thead><tbody><tr><td>March 2023</td><td>Established</td></tr><tr><td>Apache License 2.0 with commercial licensing</td><td>Open Source License</td></tr><tr><td>Over 10 full-time employees</td><td>Official R&#x26;D Team</td></tr><tr><td>Community Contributors</td><td>Over 60 people</td></tr><tr><td>Backend Technology</td><td>Python/Flask/PostgreSQL</td></tr><tr><td>Frontend Technology</td><td>Next.js</td></tr><tr><td>Codebase Size</td><td>Over 130,000 lines</td></tr><tr><td>Release Frequency</td><td>Average once per week</td></tr></tbody></table>

### Technical Features



<table data-header-hidden><thead><tr><th width="240"></th><th></th></tr></thead><tbody><tr><td>LLM Inference Engines</td><td>Dify Runtime (LangChain removed since v0.4)</td></tr><tr><td>Commercial Models Supported</td><td><strong>10+</strong>, including OpenAI and Anthropic<br>Onboard new mainstream models within 48 hours</td></tr><tr><td>MaaS Vendor Supported</td><td><strong>2</strong>, Hugging Face and Replicate</td></tr><tr><td>Local Model Inference Runtimes Supported</td><td><strong>4</strong>, Xoribits (recommended), OpenLLM, LocalAI, ChatGLM</td></tr><tr><td>Multimodal Capabilities</td><td><p>ASR Models</p><p>Rich-text models up to GPT-4V specs</p></td></tr><tr><td>Built-in App Types</td><td>Text generation, Conversational</td></tr><tr><td>Prompt-as-a-Service Orchestration</td><td><p>Visual orchestration interface widely praised, modify Prompts and preview effects in one place.<br></p><p><strong>Orchestration Modes</strong></p><ul><li>Simple orchestration</li><li>Advanced orchestration</li><li>Assistant orchestration (launching Jan 2024)</li><li>Flow orchestration (Q1 2024)</li></ul><p><strong>Prompt Variable Types</strong></p><ul><li>String</li><li>Radio enum</li><li>External API</li><li>File (Jan 2024)</li></ul></td></tr><tr><td>RAG Features</td><td><p>Industry-first visual knowledge base management interface, supporting snippet previews and recall testing.</p><p><strong>Indexing Methods</strong></p><ul><li>Keywords</li><li>Text vectors</li><li>LLM-assisted question-snippet model</li></ul><p><strong>Retrieval Methods</strong></p><ul><li>Keywords</li><li>Text similarity matching</li><li>N choose 1</li><li>Multi-path recall</li></ul><p><strong>Recall Optimization</strong></p><ul><li>Re-rank models</li></ul></td></tr><tr><td>ETL Capabilities</td><td><p>Automated cleaning for TXT, Markdown, PDF, HTML, DOC, CSV formats. Unstructured service enables maximum support.</p><p>Sync Notion docs as knowledge bases.</p></td></tr><tr><td>Vector Databases Supported</td><td>Qdrant (recommended), Weaviate, Zilliz</td></tr><tr><td>Agent Technologies</td><td><p>ReAct, Function Call.<br></p><p><strong>Tooling Support</strong></p><ul><li>Invoke OpenAI Plugin standard tools (Q4 2023)</li><li>Directly load OpenAPI Specification APIs as tools</li></ul><p><strong>Built-in Tools</strong></p><ul><li>3 tools</li></ul></td></tr><tr><td>Logging</td><td>Supported, annotations based on logs</td></tr><tr><td>Annotation Reply</td><td>Based on human-annotated Q&#x26;As, used for similarity-based replies. Exportable as data format for model fine-tuning.</td></tr><tr><td>Content Moderation</td><td>OpenAI Moderation or external APIs</td></tr><tr><td>Team Collaboration</td><td>Workspaces, multi-member management</td></tr><tr><td>API Specs</td><td>RESTful, most features covered</td></tr><tr><td>Deployment Methods</td><td>Docker, Helm</td></tr></tbody></table>
